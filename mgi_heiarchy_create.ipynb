{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPa9Q7Hln/od9ljjPeO0lkw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KravitzLab/PsygeneAnalyses/blob/PCA_analysis/mgi_heiarchy_create.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install owlready2\n",
        "#!pip install --upgrade jinja2 pyvis\n",
        "#!pip install pygraphviz"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tSftAIGCb0Yt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install and Import libraries\n",
        "\n",
        "#!pip install pronto\n",
        "#!pip install pyvis\n",
        "#!pip install sentence-transformers\n",
        "\n",
        "import os, re, zipfile\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import files\n",
        "import csv\n",
        "import pronto\n",
        "import pyvis\n",
        "import ipywidgets as widgets\n",
        "import networkx as nx\n",
        "from pyvis.network import Network\n",
        "from google.colab import files\n",
        "import networkx as nx\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.colors as mcolors\n",
        "import csv\n",
        "from sentence_transformers import SentenceTransformer, util"
      ],
      "metadata": {
        "id": "vDQuWFjhOM6Z",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Upload Ontology File\n",
        "\n",
        "\n",
        "#### Upload ontology file ####\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "#### Load ontology ####\n",
        "mp = pronto.Ontology(filename)\n",
        "\n",
        "\n",
        "# Identify roots (should only have 1 root for MGI)\n",
        "roots = [t for t in mp.terms() if not list(t.superclasses(distance=1))]\n",
        "\n",
        "\n",
        "# Depth function to calculate the minimum distance to the root\n",
        "def get_depth(term):\n",
        "    distances = []\n",
        "    for root in roots:\n",
        "        d = term.distance_from(root)\n",
        "        if d is not None:\n",
        "            distances.append(d)\n",
        "    return min(distances) if distances else 0\n",
        "\n",
        "# Calculate ancestors and descendents\n",
        "def count_ancestors(term):\n",
        "    return len(list(term.superclasses())) - 1  # subtract itself\n",
        "\n",
        "def count_descendants(term):\n",
        "    return len(list(term.subclasses())) - 1  # subtract itself\n",
        "\n",
        "def is_leaf(term):\n",
        "    return len(list(term.subclasses(distance=1))) == 0\n",
        "\n",
        "\n",
        "#### Output CSV ####\n",
        "# this is all nodes for the entire ontology\n",
        "output_file = \"ontology_edges_with_metadata.csv\"\n",
        "\n",
        "with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\n",
        "        \"parent_id\", \"parent_label\", \"parent_definition\", \"parent_depth\",\n",
        "        \"child_id\", \"child_label\", \"child_definition\", \"child_depth\",\n",
        "        \"child_is_leaf\", \"num_ancestors_child\", \"num_descendants_child\"\n",
        "    ])\n",
        "\n",
        "    for term in mp.terms():\n",
        "        parents = list(term.superclasses(distance=1))\n",
        "\n",
        "        for parent in parents:\n",
        "            writer.writerow([\n",
        "                parent.id,\n",
        "                parent.name,\n",
        "                parent.definition or \"\",\n",
        "                get_depth(parent),\n",
        "\n",
        "                term.id,\n",
        "                term.name,\n",
        "                term.definition or \"\",\n",
        "                get_depth(term),\n",
        "\n",
        "                \"yes\" if is_leaf(term) else \"no\",\n",
        "                count_ancestors(term),\n",
        "                count_descendants(term)\n",
        "            ])\n",
        "\n",
        "\n",
        "### Download the parent-child ontologies ###\n",
        "try:\n",
        "    from google.colab import files as gfiles\n",
        "except Exception:\n",
        "    gfiles = None\n",
        "\n",
        "btn = widgets.Button(description=f\"Download {os.path.basename(output_file)}\", icon=\"download\")\n",
        "status = widgets.HTML()\n",
        "def _dl(_):\n",
        "    if gfiles is not None:\n",
        "        status.value = f\"Starting download: <code>{os.path.basename(output_file)}</code>…\"\n",
        "        gfiles.download(output_file)\n",
        "    else:\n",
        "        status.value = f\"Saved locally at <code>{output_file}</code>.\"\n",
        "display(btn, status)\n",
        "btn.on_click(_dl)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NTW_nUlUQY9W",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Trim the ontology\n",
        "# define where the root starts and define how many descendents to include\n",
        "\n",
        "# crop network for only behavior and 4 ancestors (abnormal behavior is 2 down)\n",
        "# Load df\n",
        "df = pd.read_csv(\"ontology_edges_with_metadata.csv\")\n",
        "\n",
        "# Define root\n",
        "# mammalian phenotype: MP:0000001\n",
        "#root_id = 'MP:0000001'\n",
        "# abnormal behavior: MP:0004924\n",
        "root_id = 'MP:0004924'\n",
        "trim_root = mp[root_id]\n",
        "\n",
        "# Define the level of ancestries\n",
        "# 36 is the max level of ancestors a child can have (for all inclusion set to 36)\n",
        "print(df['num_ancestors_child'].max())\n",
        "anc_level = 36\n",
        "\n",
        "# Collect descendants (all depths)\n",
        "trimmed_descendants = {trim_root.id}\n",
        "trimmed_descendants.update([t.id for t in trim_root.subclasses()])\n",
        "\n",
        "# Keep only edges where BOTH parent and child are in the behavior subtree\n",
        "df_trimmed = df[\n",
        "    df[\"parent_id\"].isin(trimmed_descendants) &\n",
        "    df[\"child_id\"].isin(trimmed_descendants)\n",
        "]\n",
        "print(df_trimmed.columns)\n",
        "\n",
        "# define levels of ancetries\n",
        "df_trimmed = df_trimmed[df_trimmed[\"num_ancestors_child\"] <= anc_level]\n",
        "\n",
        "# trim self referential edges\n",
        "df_trimmed = df_trimmed[df_trimmed[\"parent_id\"] != df_trimmed[\"child_id\"]]\n",
        "df_trimmed = df_trimmed[df_trimmed[\"parent_label\"] != df_trimmed[\"child_label\"]]\n",
        "df_trimmed = df_trimmed.drop_duplicates(subset=[\"parent_id\", \"child_id\"])\n",
        "\n",
        "\n",
        "#### Download the trimmed behavior parent-child ontologies ####\n",
        "output_file = \"ontology_edges_trimmed.csv\"\n",
        "df_trimmed.to_csv(output_file, index=False)\n",
        "\n",
        "try:\n",
        "    from google.colab import files as gfiles\n",
        "except Exception:\n",
        "    gfiles = None\n",
        "\n",
        "btn = widgets.Button(description=f\"Download {os.path.basename(output_file)}\", icon=\"download\")\n",
        "status = widgets.HTML()\n",
        "def _dl(_):\n",
        "    if gfiles is not None:\n",
        "        status.value = f\"Starting download: <code>{os.path.basename(output_file)}</code>…\"\n",
        "        gfiles.download(output_file)\n",
        "    else:\n",
        "        status.value = f\"Saved locally at <code>{output_file}</code>.\"\n",
        "display(btn, status)\n",
        "btn.on_click(_dl)"
      ],
      "metadata": {
        "id": "ARxMtpUTcnqj",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Retrieve all the leaf nodes\n",
        "# Get all leaf nodes\n",
        "df_leafs = df_trimmed.copy()\n",
        "\n",
        "# All parent IDs\n",
        "all_parents = set(df_leafs[\"parent_id\"])\n",
        "\n",
        "# All child IDs\n",
        "all_children = set(df_leafs[\"child_id\"])\n",
        "\n",
        "# Leafs = children that are never parents\n",
        "leaf_nodes = all_children - all_parents\n",
        "\n",
        "# Optionally get their labels\n",
        "leaf_labels = df_leafs[df_leafs[\"child_id\"].isin(leaf_nodes)][[\"child_id\", \"child_label\", \"child_definition\"]].drop_duplicates()\n",
        "\n",
        "### Download leaf labels ###\n",
        "output_file = \"leaf_nodes.csv\"\n",
        "leaf_labels.to_csv(output_file, index=False)\n",
        "\n",
        "try:\n",
        "    from google.colab import files as gfiles\n",
        "except Exception:\n",
        "    gfiles = None\n",
        "\n",
        "btn = widgets.Button(description=f\"Download {os.path.basename(output_file)}\", icon=\"download\")\n",
        "status = widgets.HTML()\n",
        "def _dl(_):\n",
        "    if gfiles is not None:\n",
        "        status.value = f\"Starting download: <code>{os.path.basename(output_file)}</code>…\"\n",
        "        gfiles.download(output_file)\n",
        "    else:\n",
        "        status.value = f\"Saved locally at <code>{output_file}</code>.\"\n",
        "display(btn, status)\n",
        "btn.on_click(_dl)"
      ],
      "metadata": {
        "id": "Uytp5vSZDj8h",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Create a network graph for the trimmed tree above\n",
        "df_network = df_trimmed.copy()\n",
        "\n",
        "#### Build directed graph\n",
        "G = nx.DiGraph()\n",
        "\n",
        "for _, row in df_network.iterrows():\n",
        "    parent = row[\"parent_id\"]\n",
        "    child = row[\"child_id\"]\n",
        "    if parent != child:\n",
        "        G.add_edge(parent, child)\n",
        "    # Node attributes\n",
        "    G.nodes[parent]['label'] = row['parent_label']\n",
        "    G.nodes[parent]['title'] = f\"{row['parent_label']} ({parent})\\n{row['parent_definition'] or ''}\"\n",
        "    G.nodes[child]['label'] = row['child_label']\n",
        "    G.nodes[child]['title'] = f\"{row['child_label']} ({child})\\n{row['child_definition'] or ''}\"\n",
        "\n",
        "#### Remove self-loops\n",
        "G.remove_edges_from(list(nx.selfloop_edges(G)))\n",
        "\n",
        "#### Compute descendants for node size\n",
        "descendant_counts = {n: len(nx.descendants(G, n)) for n in G.nodes()}\n",
        "\n",
        "#### Assign unique colors to branches\n",
        "direct_children = list(G.successors(root_id))\n",
        "num_branches = len(direct_children)\n",
        "cmap = cm.get_cmap('tab20', num_branches)\n",
        "branch_colors = {child: mcolors.to_hex(cmap(i)) for i, child in enumerate(direct_children)}\n",
        "\n",
        "#### Propagate branch color to all nodes\n",
        "node_colors = {}\n",
        "for branch_root, color in branch_colors.items():\n",
        "    nodes_in_branch = nx.descendants(G, branch_root)\n",
        "    nodes_in_branch.add(branch_root)\n",
        "    for n in nodes_in_branch:\n",
        "        node_colors[n] = color\n",
        "\n",
        "#### Root color\n",
        "node_colors[root_id] = \"#ff9999\"  # root highlighted\n",
        "\n",
        "#### Compute node sizes (dynamic root sizing)\n",
        "node_sizes = {n: 10 + descendant_counts.get(n, 0) * 2 for n in G.nodes()}\n",
        "max_descendant_size = max(size for n, size in node_sizes.items() if n != root_id)\n",
        "node_sizes[root_id] = max_descendant_size + 3  # root slightly bigger\n",
        "\n",
        "#### Prepare edge colors (propagate branch color up to root)\n",
        "edge_colors = {}\n",
        "\n",
        "for branch_root, color in branch_colors.items():\n",
        "    # Include the edge from root -> branch_root\n",
        "    if G.has_edge(root_id, branch_root):\n",
        "        edge_colors[(root_id, branch_root)] = color\n",
        "    # All other edges in the branch\n",
        "    for u, v in nx.edge_dfs(G, branch_root):\n",
        "        edge_colors[(u, v)] = color\n",
        "\n",
        "\n",
        "#### Create PyVis network\n",
        "net = Network(\n",
        "    notebook=True,\n",
        "    directed=True,\n",
        "    height=\"800px\",\n",
        "    width=\"100%\",\n",
        "    cdn_resources='in_line'\n",
        ")\n",
        "\n",
        "# Add nodes\n",
        "for node, data in G.nodes(data=True):\n",
        "    node_label = data['label']\n",
        "    title = data['title']\n",
        "    color = node_colors.get(node, \"#66ccff\")\n",
        "    size = node_sizes.get(node, 10)\n",
        "\n",
        "    net.add_node(\n",
        "        node_label,\n",
        "        label=node_label,\n",
        "        title=title,\n",
        "        color=color,\n",
        "        size=size\n",
        "    )\n",
        "\n",
        "# Add edges with propagated branch colors\n",
        "for u, v in G.edges():\n",
        "    color = edge_colors.get((u, v), \"#66ccff\")\n",
        "    net.add_edge(G.nodes[u]['label'], G.nodes[v]['label'], color=color)\n",
        "\n",
        "#### Download\n",
        "filename = \"mgi_network.html\"\n",
        "net.show(filename)\n",
        "files.download(\"mgi_network.html\")\n"
      ],
      "metadata": {
        "id": "rsYS4b-y-fco",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Map Metrics onto the Ontology\n",
        "\n",
        "### read in the metric descriptions ###\n",
        "# need to read in the metrics list\n",
        "#### Upload defined metrics ####\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "df_metrics = pd.read_csv(filename, encoding=\"latin1\")\n",
        "\n",
        "\n",
        "# Create the model by reference\n",
        "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "model = SentenceTransformer('all-mpnet-base-v2')\n",
        "\n",
        "\n",
        "# Dummy Sentence using common key words\n",
        "t0 = \"Vecna is a Lich in DND, he has many abilities and can cast modify memory, wants to learn secrets of eveyone, and his motivation is beyond understanding.\"\n",
        "# MGI description of impaired short-term object recognition memory\n",
        "t1 = \"impaired ability of short-term memory to recognize objects during the first few minutes after training\"\n",
        "# Win-Stay Definition\n",
        "t2 = \"The ability to measure an organisms learning to stay at the device after a winning trial measuring cognition and motviation.\"\n",
        "\n",
        "# Create the embeddings\n",
        "emb0 = model.encode(t0, convert_to_tensor=True)\n",
        "emb1 = model.encode(t1, convert_to_tensor=True)\n",
        "emb2 = model.encode(t2, convert_to_tensor=True)\n",
        "\n",
        "# Find similar scores\n",
        "score0 = util.cos_sim(emb0, emb2).item()\n",
        "print(\"Dummy vs winstay Similarity:\", score0)\n",
        "score1 = util.cos_sim(emb1, emb2).item()\n",
        "print(\"Short term memory vs winstay Similarity:\", score1)\n",
        "\n",
        "\n",
        "#### Do for a matrix ####\n",
        "metric_texts = (\n",
        "    df_metrics[\"metric_name\"] + \". \" + df_metrics[\"metric_definition\"]\n",
        ").tolist()\n",
        "\n",
        "onto_texts = (\n",
        "    leaf_labels[\"child_label\"] + \". \" + leaf_labels[\"child_definition\"]\n",
        ").tolist()\n",
        "\n",
        "metric_emb = model.encode(metric_texts, convert_to_tensor=True)\n",
        "onto_emb = model.encode(onto_texts, convert_to_tensor=True)\n",
        "\n",
        "\n",
        "# compute the similarity matrix\n",
        "sim_matrix = util.cos_sim(metric_emb, onto_emb)\n",
        "\n",
        "\n",
        "# Extract the top matches\n",
        "# Define similarity threshold score\n",
        "threshold = 0.4\n",
        "top_k = 5\n",
        "\n",
        "filtered_matches = []\n",
        "\n",
        "for i, mrow in df_metrics.iterrows():\n",
        "    scores = sim_matrix[i]\n",
        "\n",
        "    # top-k candidate ontology indices\n",
        "    top_idx = scores.topk(top_k).indices.tolist()\n",
        "\n",
        "    for idx in top_idx:\n",
        "        score_val = float(scores[idx])\n",
        "\n",
        "        if score_val >= threshold:\n",
        "            filtered_matches.append({\n",
        "                \"metric_id\": mrow[\"metric_id\"],\n",
        "                \"metric_name\": mrow[\"metric_name\"],\n",
        "                \"metric_definition\": mrow[\"metric_definition\"],\n",
        "                \"ontology_id\": leaf_labels[\"child_id\"].iloc[idx],\n",
        "                \"ontology_term\": leaf_labels[\"child_label\"].iloc[idx],\n",
        "                \"ontology_definition\": leaf_labels[\"child_definition\"].iloc[idx],\n",
        "                \"similarity\": score_val\n",
        "            })\n",
        "\n",
        "filtered_df = pd.DataFrame(filtered_matches)\n",
        "filtered_df.head()\n",
        "\n",
        "\n",
        "\n",
        "### Download mapped metrics ###\n",
        "output_file = \"onto_metrics_mapped.csv\"\n",
        "filtered_df.to_csv(output_file, index=False)\n",
        "\n",
        "try:\n",
        "    from google.colab import files as gfiles\n",
        "except Exception:\n",
        "    gfiles = None\n",
        "\n",
        "btn = widgets.Button(description=f\"Download {os.path.basename(output_file)}\", icon=\"download\")\n",
        "status = widgets.HTML()\n",
        "def _dl(_):\n",
        "    if gfiles is not None:\n",
        "        status.value = f\"Starting download: <code>{os.path.basename(output_file)}</code>…\"\n",
        "        gfiles.download(output_file)\n",
        "    else:\n",
        "        status.value = f\"Saved locally at <code>{output_file}</code>.\"\n",
        "display(btn, status)\n",
        "btn.on_click(_dl)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wEtcCHAYKzqE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}